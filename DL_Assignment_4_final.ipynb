{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adityamishra5050/NASWOT-on-CIFAR-10/blob/main/DL_Assignment_4_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMFfIUPxtU2r",
        "outputId": "1a0e2eec-a1cd-455d-ac09-2f8d5334dace"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4eb97f55e7a8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here we are importing the google drive librery for mounting the google drive for cloning the libraries and the dataset storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Here we are importing the google drive librery for mounting the google drive for cloning the libraries and the dataset storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud9khZFqupQ-",
        "outputId": "2cf9fc04-97f4-46aa-8ae8-085cdf020b35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting conda\n",
            "  Downloading conda-4.3.16.tar.gz (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycosat>=0.6.1\n",
            "  Downloading pycosat-0.6.3.zip (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.9/dist-packages (from conda) (2.27.1)\n",
            "Collecting ruamel.yaml>=0.11.14\n",
            "  Downloading ruamel.yaml-0.17.21-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.12.4->conda) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.12.4->conda) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.12.4->conda) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.12.4->conda) (1.26.15)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.4/519.4 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: conda, pycosat\n",
            "  Building wheel for conda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for conda: filename=conda-4.3.16-py3-none-any.whl size=336958 sha256=cb3c915e89b2c142dc83c351104ff3be1668a4db3f782341f6639e0b71ae7280\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/96/b0/3260315d5b6f74397510d6b3eb6ccde93623a6bdd9e180ee61\n",
            "  Building wheel for pycosat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycosat: filename=pycosat-0.6.3-cp39-cp39-linux_x86_64.whl size=169868 sha256=46b35d832fc4dbcff908a6e9b9f6688d6b9f8fb58419554e18d4b5af63d9e8f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/c4/34/9ccbaac74c64deb727e916d00905158b6941b006bc829fa7fe\n",
            "Successfully built conda pycosat\n",
            "Installing collected packages: pycosat, ruamel.yaml.clib, ruamel.yaml, conda\n",
            "Successfully installed conda-4.3.16 pycosat-0.6.3 ruamel.yaml-0.17.21 ruamel.yaml.clib-0.2.7\n"
          ]
        }
      ],
      "source": [
        "# as recommended in the readme file in the github page that we ahve to make the conda environment so we are installing the conda environment for making the conda set for the seam less flow of the code\n",
        "!pip install conda\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGRoq3MuvL2r",
        "outputId": "0775015d-24b6-4e66-e92b-eff06122c356"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# here we are importing the subprocess library which will help us in making the conda environment in the implementatation and it will maintain that conda environment overall in the process\n",
        "import subprocess\n",
        "subprocess.call('conda env create -f env.yml', shell=True)# here we are creating the conda environment for the process\n",
        "subprocess.call('conda activate env.yml', shell=True)# here we are activating that conda environment for the tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "937fc-l-JIyo",
        "outputId": "63142bc5-ad8c-40f0-9be9-2edb4f30bfad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow-1.12.0 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow-1.12.0\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-1.12.0 # here we are trying the to install the tensorflow versoin of the version of 1.x which is required for implementing the codes written in the library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6XesotVtOe2",
        "outputId": "5764bf88-442f-45bd-e9a5-60178944a5b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  498M  100  498M    0     0  56.1M      0  0:00:08  0:00:08 --:--:-- 58.8M\n",
            "Cloning into 'nasbench'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Total 96 (delta 0), reused 0 (delta 0), pack-reused 96\u001b[K\n",
            "Unpacking objects: 100% (96/96), 348.37 KiB | 3.29 MiB/s, done.\n",
            "\u001b[31mERROR: Invalid requirement: './nasbench#'\n",
            "Hint: It looks like a path. File './nasbench#' does not exist.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# here we are cloning the nasbench 108 as we instructed in the readme file of the code\n",
        "\n",
        "!curl -O https://storage.googleapis.com/nasbench/nasbench_only108.tfrecord\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "!git clone https://github.com/google-research/nasbench\n",
        "!pip install ./nasbench# here we are installing the nasbench\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKn1_8xovKm5",
        "outputId": "3eb87de7-1b83-46da-96c0-6a7915271591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd # here we are seeing the status of the cntent drive of the google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn6pLR166IKE"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/naswot-codebase/nds_data/ # here we are making the directory as it was instructed in the instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osCBXtP34JAo"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/MyDrive/DL_assignment_4_dataset/nds_data\" \"/content/naswot-codebase/nds_data/\" # here we are joining the dataset with the directory of the dataset with the given file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgKfZM-R8-Wk",
        "outputId": "a8906e5e-b387-4d42-b06b-ba1e65bbe06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'nas-without-training'...\n",
            "remote: Enumerating objects: 282, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 282 (delta 42), reused 37 (delta 37), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (282/282), 911.42 KiB | 6.96 MiB/s, done.\n",
            "Resolving deltas: 100% (113/113), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BayesWatch/nas-without-training.git # here we are cloning the research paper library nas-without training for the seamless flow of the code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRzWJTGp42mV"
      },
      "outputs": [],
      "source": [
        "!chmod +x /content/nas-without-training/scorehook.sh # here we are giving the command of the given instruction in the readme file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6oqX12yAQ8k"
      },
      "outputs": [],
      "source": [
        "%cd /content/nas-without-training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCEjiCz6MTZB"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x # here we are trying the tensorflow version of the 1.x for the implementataion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei7QfsUlAupo"
      },
      "outputs": [],
      "source": [
        "!python3 score_networks.py --json_file_path=/content/naswot-codebase/nds_data/nds_data/ResNet.json --ckpt_file_path=/content/nas-without-training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZIrVTFi8wtq"
      },
      "outputs": [],
      "source": [
        "!/content/nas-without-training/scorehook.sh --json_file_path=/content/naswot-codebase/nds_data/nds_data/ResNet.json --ckpt_file_path=/content/nas-without-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGr6rpskXdeM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "'''\n",
        "The model architecture should satisfy the following conditions:\n",
        "1. Number of neurons in the output layer: Equal to the number of classes\n",
        "2. Activation function: Sigmoid (except in the output layer); Softmax in the output layer\n",
        "3. Optimization algorithm: Gradient Descent (to be coded from scratch; you may use the code from\n",
        "previous assignments)\n",
        "4. Weight initialization: Random\n",
        "5. Loss function: Categorical Crossentropy\n",
        "6. Evaluation metrics: Accuracy\n",
        "7. Train-test split: Standard protocol\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYs4a_jL6IJp"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "\n",
        "import random\n",
        "\n",
        "# here we are using the torch n module for the resnet model\n",
        "\n",
        "# since we using the Pytorch only so we are importing the torch\n",
        "import torch\n",
        "# since we are using the torch vision neural network module for the nn module which is previously defined in the pytorch library\n",
        "import torch.nn as nn\n",
        "# we are using the pytorch inbuilt library for the nn module which is functional for the function related values taking care of the tensor of th dataset of my values dataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# here we are iporting the library of the torch named as utils and inside it we are using the Dataset function which will be taking care of my Dataset of the given instruction\n",
        "from torch.utils.data import Dataset\n",
        "# here we are importing the Dataloader function , by the use of it we can load our dataset to the model\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "# as we know tha if we are working with the pytorch so we have to be prepared fot preparing our dataset in the tensor form for the seamlessly flow of the dataset, so that we are using the transforms function or keyword by the use of it we can transform our data into the tensors\n",
        "from torchvision import transforms\n",
        "\n",
        "# the os library is just imported for the openning of my image dataset for the tensors form for the use of the pytorch\n",
        "import os\n",
        "# the time library is just imported because we can use it as for showing the total time of execution\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8QJ_qmQAPiq"
      },
      "outputs": [],
      "source": [
        "# sigmoid activation function\n",
        "def sigmoid(x):\n",
        "     return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ng2Mk4T0-6Ds"
      },
      "outputs": [],
      "source": [
        "def hid_fun(input_data,Weight1,bias1):\n",
        "    '''\n",
        "    Layer_1 = input layer , Layer_2 = hidden layer, with a size implied by the arguments Weight[0], bias , Layer_3 = output layer, with Weight[1]\n",
        "    '''\n",
        "    # passing the input layer\n",
        "    input1 = input_data\n",
        "    # layer_1 to layer_2\n",
        "    output1 = np.matmul(input_data, Weight1[0]) + bias1[0]\n",
        "\n",
        "    input2 = sigmoid(output1)\n",
        "    # layer_2 to layer_3\n",
        "    output2 = np.matmul(input2, Weight1[1])\n",
        "    expo_s1 = np.exp(output2)\n",
        "    total = np.sum(expo_s1, axis=1).reshape(-1,1)\n",
        "    result_expo = expo_s1/total\n",
        "    # this is the probability of each data sample given in the data det impleted by the above operations\n",
        "    return result_expo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpf7RDFr7BHy"
      },
      "outputs": [],
      "source": [
        "def softmax(input_data1,weight3):\n",
        "\n",
        "    expo_s2 = np.exp(np.matmul(input_data1,weight3))\n",
        "    total = np.sum(expo_s2, axis=1).reshape(-1,1)\n",
        "    return expo_s2 / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2Odt3lc7EZ3"
      },
      "outputs": [],
      "source": [
        "def cross_loss(pred_value,given_value):\n",
        "    '''\n",
        "    K is the number of classes which should be the globel variable for the furthur operations\n",
        "    '''\n",
        "    global K\n",
        "    K = 10\n",
        "    N = len(given_value)\n",
        "    given_value_one_hot_vec = (given_value[:,np.newaxis] == np.arange(K))\n",
        "    loss_data = (np.log(pred_value) * given_value_one_hot_vec).sum(axis=1)\n",
        "    return -np.mean(loss_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zV9dMMv27Hkv"
      },
      "outputs": [],
      "source": [
        "def backprop(Weight2,bias2,input_data2,y_train_data,regu_factor=1e-4):\n",
        "    '''\n",
        "    Step 1: implement forward propogation hid_fun(input_data,Weight1,bias1)\n",
        "    Step 2: implement backpropagation for dWeight and dbias\n",
        "    '''\n",
        "    K = 10\n",
        "    N = input_data2.shape[0]\n",
        "\n",
        "    # passing the input layer\n",
        "    input1 = input_data2\n",
        "    # layer_1 to layer_2\n",
        "    output1 = np.matmul(input_data2, Weight2[0]) + bias2[0]\n",
        "    # layer_2 activation\n",
        "    input2 = sigmoid(output1)\n",
        "\n",
        "\n",
        "    # layer_2 to layer_3\n",
        "    output2 = np.matmul(input2, Weight2[1])\n",
        "    expo_s3 = np.exp(output2)\n",
        "    total = np.sum(expo_s3, axis=1).reshape(-1,1)\n",
        "    result_expo1 = expo_s3/total\n",
        "\n",
        "\n",
        "    # layer_2 to layer_3 weights' derivative\n",
        "    # parti_2 is \\partial L/partial output2, of shape (N,K)\n",
        "    y_train_data_hot_vec = (y_train_data[:,np.newaxis] == np.arange(K))\n",
        "    parti_2 = (result_expo1 - y_train_data_hot_vec)\n",
        "    grad_Weight1 = np.matmul(input2.T, parti_2)\n",
        "\n",
        "    # layer_1 to layer_2 weights' derivative\n",
        "    # parti_1 is \\partial a2/partial output1\n",
        "\n",
        "    parti_1 = np.matmul(parti_2, Weight2[1].T)*(output1>0)\n",
        "    grad_Weight0 = np.matmul(input_data2.T, parti_1)\n",
        "\n",
        "\n",
        "\n",
        "    dWeight = [grad_Weight0/N + regu_factor*Weight2[0], grad_Weight1/N + regu_factor*Weight2[1]]\n",
        "    dbias = [np.mean(parti_1, axis=0)]\n",
        "    # dWeight[0] is Weight[0]'s derivative, and dWeight[1] is Weight[1]'s derivative; similar for dbias\n",
        "    return dWeight, dbias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_s4G0On7W7K"
      },
      "outputs": [],
      "source": [
        "chii = 5e-1\n",
        "regu_factor1 = 1e-6 # regularization factor 1\n",
        "learn_rate0 = 0.01 # learning rate η\n",
        "eps = 1e-3 #epsilon\n",
        "Epoch0 = 20 # number of Epoch\n",
        "K = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E01wwcrr7fIb"
      },
      "outputs": [],
      "source": [
        "# initialization\n",
        "np.random.seed(1127)\n",
        "\n",
        "random_bias0 = [np.random.randn(n_H0)]\n",
        "results0 = pd.DataFrame(columns=[\"Loss\", \"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTdeZEhxCbis"
      },
      "outputs": [],
      "source": [
        "# Since my image dataset and their respective attributes are place not together so we ate joining them and preparing the dataset of the combination of the both\n",
        "# so that in future time when we train the model it will get the training dataset as the tuple of my image dataset and the its taget labels\n",
        "# since it is the heavy task , to full fill our wish we have to prepare a class of the joining my dataset\n",
        "\n",
        "class joinig_my_dataset_and_labels(Dataset): # here we are making my desired class for joining my dataset for the use of the futher processing\n",
        "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
        "# here we are gonna define a init function for the transformation of my values of the dataset in a way that can be used in the future\n",
        "    def __init__(self, csv_path, img_dir, transform=None):\n",
        "    # as we are passing the arguments in the form of the clas so my argumrnts keywords are as csv_path for the path taking for the csv file for passing it to the defined function\n",
        "    # we are passing an argument as the imageset directory and the this argument will be passed to the defined function above\n",
        "    # here we are passing an argument the transform as none by some means\n",
        "        mydrame = pd.read_csv(csv_path, index_col=0) # here we acreating a dataset as the mydrame whivh will contain my csv file\n",
        "        self.img_dir = img_dir # here we are giving the image directory as argument to the function as we have written above\n",
        "        self.csv_path = csv_path # here we are passing the csv_path of the my dataset file which we will be passing in our future\n",
        "        self.img_names = mydrame.index.values # here it is creating the index values of my image dataset for the further values\n",
        "        self.y = mydrame.values # here we are passing the values of the dataset of the dataframe which we have created before\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index): # actually in this part of the code we are joining the dataset with the image dataset and its label set which we prepaed as the taget values\n",
        "        # here is the complete image with its label set which will be used further in this coding\n",
        "        my_prep_image_is = Image.open(os.path.join(self.img_dir,self.img_names[index])) #here we are opening the image one by one and joining all the images with their target labels as given above\n",
        "\n",
        "        if self.transform is not None:\n",
        "            my_prep_image_is = self.transform(my_prep_image_is)\n",
        "\n",
        "        my_prep_target_value_is = self.y[index] # here we are passing the index values to my image which will be used as the reference of the image\n",
        "        return my_prep_image_is, my_prep_target_value_is # here we are returning the my image prepared and its label for the code\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvCfnILvpwdv"
      },
      "outputs": [],
      "source": [
        "# here we making the LSTM encoder class for the encoding purposes of the sequencialy inputted dataset\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,capacity_of_size_taking_input,capacity_of_size_of_taking_embedding,number_of_neuron_in_hidden_layer,number_of_hidden_layer,Dropout_ration_number): # here we defining the init function which is taking the input size, embedding size, hidden size , number of hidden layers,and the dropout ration\n",
        "        super(Encoder,self).__init__() # here we are appling the Encoder function initself for the loop purposes\n",
        "        self.hidden_size = number_of_neuron_in_hidden_layer # here we are defining the hidden size of the LSTM encoder\n",
        "        self.num_layers = number_of_hidden_layer   # here we are defining the number of the hidden layer in the network\n",
        "\n",
        "        self.dropout = nn.Dropout(Dropout_ration_number)   # here we defining the dropout ration of the linear network\n",
        "        self.embedding = nn.Embedding(capacity_of_size_taking_input,capacity_of_size_of_taking_embedding) # here we passing the input size and the embedding size to nn module of the embedding\n",
        "        self.rnn = nn.LSTM(capacity_of_size_of_taking_embedding,hidden_size,num_layers, dropout=Dropout_ration_number)  # here we are passing the argumrnt to the LSTM nn module as the embedding size , hidden size , number of thr hidden layer and the drpout ratio\n",
        "\n",
        "    def forward(self,input_x_for_the_embedding): # here we are defining the forward function for the Encoder which will pass all the information to the next part for the further processing\n",
        "        # here we are passing the argumrnt as the input vector length\n",
        "\n",
        "        embedding = self.dropout(self.embedding(input_x_for_the_embedding)) # here we are passing the information of the embedding of the input layer\n",
        "\n",
        "\n",
        "        outputs, (hidden_state_number_of_the_LSTM,cell_state_number_of_the_LSTM) = self.rnn(embedding) # here we are getting the output, hidden state and the cell state\n",
        "\n",
        "        return hidden_state_number_of_the_LSTM, cell_state_number_of_the_LSTM # herewe are returning these hidden amd and cell state of the LSTM to the next part for the further processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4_D2Gz1py1B"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module): # here we are defining the Decoder nn module for the LSTM completion so that it can decode the next word by the prediction of the next term\n",
        "    def __init__(self,capacity_of_size_taking_input,capacity_of_size_of_taking_embedding,number_of_neuron_in_hidden_layer,output_size,number_of_hidden_layer,Dropout_ration_number): # here we are defining the init function and passing the argumrnts as the input size,embeding size, hidden size, output,, number of layers and thr dropout ration\n",
        "        super(Decoder,self).__init__() # here we are the decoder function for the loop stream working\n",
        "        self.hidden_size = number_of_neuron_in_hidden_layer # here we are passing the hidden size argument to the Decoder\n",
        "        self.num_layers = number_of_hidden_layer # here we are defining thre number of layer as the arguent of the DEcoder\n",
        "\n",
        "        self.dropout = nn.Dropout(Dropout_ration_number) # here efining the the number of the dropout ration\n",
        "        self.embedding = nn.Embedding(capacity_of_size_taking_input,capacity_of_size_of_taking_embedding) # here we are giving the argument as the input size and the embedding size\n",
        "        self.rnn = nn.LSTM(capacity_of_size_of_taking_embedding,hidden_size,number_of_hidden_layer,dropout=Dropout_ration_number) #here we are passing the argument to the nn module of the LSTM and these arguments are as embedding size,hidden size,number of layer,and the dropout ration\n",
        "        self.fc = nn.Linear(number_of_neuron_in_hidden_layer,output_size) # here we are defining the fully connected layer and passing the arguments as the hidden size and the output size\n",
        "\n",
        "    def forward(self, input_x_for_the_embedding, hidden_state_number_of_the_LSTM, cell_state_number_of_the_LSTM): #here we are defining the forward function which will pass all the information to the further processing\n",
        "        # here we are unsquuezing the value of the argument passed to this function\n",
        "        input_x_for_the_embedding = input_x_for_the_embedding.unsqueeze(0)\n",
        "\n",
        "        embedding = self.dropout(self.embedding(input_x_for_the_embedding)) # here we are defining the embedding tof the input and we are using it as the embedding by applying the dropout function to it.\n",
        "\n",
        "        outputs, (hidden_state_number_of_the_LSTM, cell_state_number_of_the_LSTM) = self.rnn(embedding,(hidden_state_number_of_the_LSTM,cell_state_number_of_the_LSTM)) # here we are getting thye output hidden state and the cell state of the LSTM which will be pass on the LSTM\n",
        "\n",
        "        we_are_making_predictions_as = self.fc(outputs) # here we are defining the fully connected layers for the output and getting the prediction of the input sequence\n",
        "        # predictions : ( 1, N, length_vocab)\n",
        "\n",
        "        we_are_making_predictions_as = we_are_making_predictions_as.squeeze(0) # here we are squeezing the result of the prediction value for the further processing\n",
        "\n",
        "        return we_are_making_predictions_as, hidden_state_number_of_the_LSTM, cell_state_number_of_the_LSTM # now we are returning the prediction value, hidden state and the cell state of the LSTM for the further processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtczfcrN9hfm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc8O2DIqx5KJ"
      },
      "outputs": [],
      "source": [
        "def test_model(model, dataloaders, criterion, optimizer, device, num_epochs=1, is_train=True):\n",
        "    since = time.time()\n",
        "\n",
        "    my_accuracicy_list_for_mod_history = []\n",
        "    my_loss_list_for_mod_history = []\n",
        "\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "        my_loss_for_running_model_is = 0.0\n",
        "        how_much_correct_in_running_model = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in dataloaders:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            model.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # statistics\n",
        "            my_loss_for_running_model_is += loss.item() * inputs.size(0)\n",
        "            how_much_correct_in_running_model += torch.sum(preds == labels.data)\n",
        "\n",
        "        my_loss_for_single_epoch = my_loss_for_running_model_is / len(dataloaders.dataset)\n",
        "        my_accuracy_for_single_epoch = how_much_correct_in_running_model.double() / len(dataloaders.dataset)\n",
        "\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(my_loss_for_single_epoch, my_accuracy_for_single_epoch))\n",
        "\n",
        "        if my_accuracy_for_single_epoch > best_acc:\n",
        "            best_acc = my_accuracy_for_single_epoch\n",
        "\n",
        "        my_accuracicy_list_for_mod_history.append(my_accuracy_for_single_epoch.item())\n",
        "        my_loss_list_for_mod_history.append(my_loss_for_single_epoch)\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    return my_accuracicy_list_for_mod_history, my_loss_list_for_mod_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJB9Fs2VloIN"
      },
      "outputs": [],
      "source": [
        "# Since my image dataset and their respective attributes are place not together so we ate joining them and preparing the dataset of the combination of the both\n",
        "# so that in future time when we train the model it will get the training dataset as the tuple of my image dataset and the its taget labels\n",
        "# since it is the heavy task , to full fill our wish we have to prepare a class of the joining my dataset\n",
        "\n",
        "class joinig_my_dataset_and_labels(Dataset): # here we are making my desired class for joining my dataset for the use of the futher processing\n",
        "    \"\"\"Custom Dataset for loading CelebA face images\"\"\"\n",
        "# here we are gonna define a init function for the transformation of my values of the dataset in a way that can be used in the future\n",
        "    def __init__(self, csv_path, img_dir, transform=None):\n",
        "    # as we are passing the arguments in the form of the clas so my argumrnts keywords are as csv_path for the path taking for the csv file for passing it to the defined function\n",
        "    # we are passing an argument as the imageset directory and the this argument will be passed to the defined function above\n",
        "    # here we are passing an argument the transform as none by some means\n",
        "        mydrame = pd.read_csv(csv_path, index_col=0) # here we acreating a dataset as the mydrame whivh will contain my csv file\n",
        "        self.img_dir = img_dir # here we are giving the image directory as argument to the function as we have written above\n",
        "        self.csv_path = csv_path # here we are passing the csv_path of the my dataset file which we will be passing in our future\n",
        "        self.img_names = mydrame.index.values # here it is creating the index values of my image dataset for the further values\n",
        "        self.y = mydrame.values # here we are passing the values of the dataset of the dataframe which we have created before\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index): # actually in this part of the code we are joining the dataset with the image dataset and its label set which we prepaed as the taget values\n",
        "        # here is the complete image with its label set which will be used further in this coding\n",
        "        my_prep_image_is = Image.open(os.path.join(self.img_dir,self.img_names[index])) #here we are opening the image one by one and joining all the images with their target labels as given above\n",
        "\n",
        "        if self.transform is not None:\n",
        "            my_prep_image_is = self.transform(my_prep_image_is)\n",
        "\n",
        "        my_prep_target_value_is = self.y[index] # here we are passing the index values to my image which will be used as the reference of the image\n",
        "        return my_prep_image_is, my_prep_target_value_is # here we are returning the my image prepared and its label for the code\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WqiKuTplsEF"
      },
      "outputs": [],
      "source": [
        "def test_model(model, dataloaders, criterion, optimizer, device, num_epochs=1, is_train=True):\n",
        "    since = time.time()\n",
        "\n",
        "    my_accuracicy_list_for_mod_history = []\n",
        "    my_loss_list_for_mod_history = []\n",
        "\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "        my_loss_for_running_model_is = 0.0\n",
        "        how_much_correct_in_running_model = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in dataloaders:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            model.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # statistics\n",
        "            my_loss_for_running_model_is += loss.item() * inputs.size(0)\n",
        "            how_much_correct_in_running_model += torch.sum(preds == labels.data)\n",
        "\n",
        "        my_loss_for_single_epoch = my_loss_for_running_model_is / len(dataloaders.dataset)\n",
        "        my_accuracy_for_single_epoch = how_much_correct_in_running_model.double() / len(dataloaders.dataset)\n",
        "\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(my_loss_for_single_epoch, my_accuracy_for_single_epoch))\n",
        "\n",
        "        if my_accuracy_for_single_epoch > best_acc:\n",
        "            best_acc = my_accuracy_for_single_epoch\n",
        "\n",
        "        my_accuracicy_list_for_mod_history.append(my_accuracy_for_single_epoch.item())\n",
        "        my_loss_list_for_mod_history.append(my_loss_for_single_epoch)\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    return my_accuracicy_list_for_mod_history, my_loss_list_for_mod_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXrDimc3lzWy"
      },
      "outputs": [],
      "source": [
        "def hid_fun(input_data,Weight1,bias1):\n",
        "    '''\n",
        "    Layer_1 = input layer , Layer_2 = hidden layer, with a size implied by the arguments Weight[0], bias , Layer_3 = output layer, with Weight[1]\n",
        "    '''\n",
        "    # passing the input layer\n",
        "    input1 = input_data\n",
        "    # layer_1 to layer_2\n",
        "    output1 = np.matmul(input_data, Weight1[0]) + bias1[0]\n",
        "\n",
        "    input2 = sigmoid(output1)\n",
        "    # layer_2 to layer_3\n",
        "    output2 = np.matmul(input2, Weight1[1])\n",
        "    expo_s1 = np.exp(output2)\n",
        "    total = np.sum(expo_s1, axis=1).reshape(-1,1)\n",
        "    result_expo = expo_s1/total\n",
        "    # this is the probability of each data sample given in the data det impleted by the above operations\n",
        "    return result_expo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAcjvwU6l1pK"
      },
      "outputs": [],
      "source": [
        "def test_model(model, dataloaders, criterion, optimizer, device, num_epochs=1, is_train=True):\n",
        "    since = time.time()\n",
        "\n",
        "    my_accuracicy_list_for_mod_history = []\n",
        "    my_loss_list_for_mod_history = []\n",
        "\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "        my_loss_for_running_model_is = 0.0\n",
        "        how_much_correct_in_running_model = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in dataloaders:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            model.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # statistics\n",
        "            my_loss_for_running_model_is += loss.item() * inputs.size(0)\n",
        "            how_much_correct_in_running_model += torch.sum(preds == labels.data)\n",
        "\n",
        "        my_loss_for_single_epoch = my_loss_for_running_model_is / len(dataloaders.dataset)\n",
        "        my_accuracy_for_single_epoch = how_much_correct_in_running_model.double() / len(dataloaders.dataset)\n",
        "\n",
        "        print('Loss: {:.4f} Acc: {:.4f}'.format(my_loss_for_single_epoch, my_accuracy_for_single_epoch))\n",
        "\n",
        "        if my_accuracy_for_single_epoch > best_acc:\n",
        "            best_acc = my_accuracy_for_single_epoch\n",
        "\n",
        "        my_accuracicy_list_for_mod_history.append(my_accuracy_for_single_epoch.item())\n",
        "        my_loss_list_for_mod_history.append(my_loss_for_single_epoch)\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    return my_accuracicy_list_for_mod_history, my_loss_list_for_mod_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB-LAhBmlpdn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}